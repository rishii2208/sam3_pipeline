{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5aafb3d8",
   "metadata": {},
   "source": [
    "**Prerequisites**\n",
    "- Git repository that contains this project (push your local changes somewhere accessible).\n",
    "- Hugging Face access token with permission to pull SAM3 weights.\n",
    "- Kaggle API token (kaggle.json) if you want the notebook to download the fruits dataset automatically, otherwise mount Google Drive and point to an existing copy of `data/fruits`.\n",
    "- Colab runtime set to GPU (Runtime → Change runtime type → Hardware accelerator → GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fcb720d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: nvidia-smi: command not found\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05735b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Runtime configuration\n",
    "REPO_URL = \"https://github.com/rishii2208/sam3_pipeline.git\"  #@param {type:\"string\"}\n",
    "PROJECT_DIR = \"/content/readme\"  #@param {type:\"string\"}\n",
    "MOUNT_DRIVE = False  #@param {type:\"boolean\"}\n",
    "DRIVE_DATASET_PATH = \"/content/drive/MyDrive/datasets/fruits\"  #@param {type:\"string\"}\n",
    "DOWNLOAD_WITH_KAGGLE = True  #@param {type:\"boolean\"}\n",
    "TRAIN_DEVICE = \"cuda\"  #@param [\"cuda\", \"cpu\"]\n",
    "CALIBRATION_LIMIT = 0  #@param {type:\"integer\"}\n",
    "EVAL_LIMIT = 0  #@param {type:\"integer\"}\n",
    "PIPELINES = [\"p2\", \"p3\"]\n",
    "assert REPO_URL, \"Set REPO_URL to your Git repository URL.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09f6d617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/readme\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/readme/scripts/train.py\", line 5, in <module>\n",
      "    from src.pipelines.runner import PipelineRunner\n",
      "ModuleNotFoundError: No module named 'src'\n"
     ]
    }
   ],
   "source": [
    "%cd /content/readme\n",
    "!python scripts/train.py --pipeline p2 --device cuda --limit 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6749240f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/readme\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/readme/scripts/train.py\", line 5, in <module>\n",
      "    from src.pipelines.runner import PipelineRunner\n",
      "  File \"/content/readme/src/pipelines/runner.py\", line 13, in <module>\n",
      "    from src.data.dataset import FruitsDataset\n",
      "ModuleNotFoundError: No module named 'src.data'\n"
     ]
    }
   ],
   "source": [
    "%cd /content/readme\n",
    "import os\n",
    "os.environ[\"PYTHONPATH\"] = \"/content/readme\"\n",
    "!python scripts/train.py --pipeline p2 --device cuda --limit 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "449a7c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/readme\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/readme/scripts/train.py\", line 5, in <module>\n",
      "    from src.pipelines.runner import PipelineRunner\n",
      "  File \"/content/readme/src/pipelines/runner.py\", line 13, in <module>\n",
      "    from src.data.dataset import FruitsDataset\n",
      "ModuleNotFoundError: No module named 'src.data'\n"
     ]
    }
   ],
   "source": [
    "%cd /content/readme\n",
    "!PYTHONPATH=/content/readme python scripts/train.py --pipeline p2 --device cuda --limit 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9125568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token captured? True\n"
     ]
    }
   ],
   "source": [
    "#@title Enter authentication tokens (input hidden after execution)\n",
    "import getpass\n",
    "HF_TOKEN = getpass.getpass(\"Hugging Face token (leave blank to skip): \" ).strip()\n",
    "print(\"Token captured?\", bool(HF_TOKEN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed2f82b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MOUNT_DRIVE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1405888926.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#@title Optional: mount Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mMOUNT_DRIVE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MOUNT_DRIVE' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "119bcf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '/content/readme'...\n",
      "remote: Enumerating objects: 29, done.\u001b[K\n",
      "remote: Counting objects: 100% (29/29), done.\u001b[K\n",
      "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
      "remote: Total 29 (delta 1), reused 29 (delta 1), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (29/29), 15.03 KiB | 3.00 MiB/s, done.\n",
      "Resolving deltas: 100% (1/1), done.\n",
      "/content/readme\n",
      "remote: Enumerating objects: 29, done.\u001b[K\n",
      "remote: Counting objects: 100% (29/29), done.\u001b[K\n",
      "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
      "remote: Total 29 (delta 1), reused 29 (delta 1), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (29/29), 15.03 KiB | 3.00 MiB/s, done.\n",
      "Resolving deltas: 100% (1/1), done.\n",
      "/content/readme\n"
     ]
    }
   ],
   "source": [
    "#@title Clone (or re-clone) the repository\n",
    "import pathlib\n",
    "import shutil\n",
    "project_path = pathlib.Path(PROJECT_DIR)\n",
    "if project_path.exists():\n",
    "    print(f'Removing existing directory: {project_path}')\n",
    "    shutil.rmtree(project_path)\n",
    "!git clone {REPO_URL} {PROJECT_DIR}\n",
    "%cd {PROJECT_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5514930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m874.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/779.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m874.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m115.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m115.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m725.0/725.0 kB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m120.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m725.0/725.0 kB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m120.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m169.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m169.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m912.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m912.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:05\u001b[0m\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/823.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m783.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m783.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:03\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:02\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.7/39.7 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.7/39.7 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for kaggle (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for kaggle (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.9.0+cpu requires torch==2.9.0, but you have torch 2.3.1 which is incompatible.\n",
      "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.9.0+cpu requires torch==2.9.0, but you have torch 2.3.1 which is incompatible.\n",
      "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: file:///content/readme/external/sam3 does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: file:///content/readme/external/sam3 does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/168.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "#@title Install Python dependencies (includes SAM3 + Triton)\n",
    "%pip install -q -r requirements.txt\n",
    "%pip install -q -e external/sam3[train]\n",
    "%pip install -q triton==2.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c300b9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Authenticate with Hugging Face\n",
    "if HF_TOKEN:\n",
    "    from huggingface_hub import login\n",
    "    login(token=HF_TOKEN, add_to_git_credential=False)\n",
    "else:\n",
    "    print('HF token not provided; assuming checkpoints already cached.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2501cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credential file exists? False\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "cred_path = Path.home() / \"kaggle.json\"\n",
    "print(\"Credential file exists?\", cred_path.exists())\n",
    "if cred_path.exists():\n",
    "    cred_path.chmod(0o600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "926cc904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.8.0 / client 1.6.17)\n",
      "Dataset URL: https://www.kaggle.com/datasets/afsananadia/fruits-images-dataset-object-detection\n",
      "License(s): CC0-1.0\n",
      "Downloading fruits-images-dataset-object-detection.zip to /content/readme/data/fruits\n",
      "  7% 5.00M/70.2M [00:00<00:02, 32.2MB/s]Downloading fruits-images-dataset-object-detection.zip to /content/readme/data/fruits\n",
      " 85% 60.0M/70.2M [00:00<00:00, 88.9MB/s]\n",
      "100% 70.2M/70.2M [00:00<00:00, 93.4MB/s]\n",
      " 85% 60.0M/70.2M [00:00<00:00, 88.9MB/s]\n",
      "100% 70.2M/70.2M [00:00<00:00, 93.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "#@title Prepare the fruits dataset\n",
    "import json\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "project_path = Path(PROJECT_DIR)\n",
    "data_root = project_path / 'data' / 'fruits'\n",
    "data_root.mkdir(parents=True, exist_ok=True)\n",
    "home_kaggle_dir = Path.home() / '.kaggle'\n",
    "home_kaggle_dir.mkdir(exist_ok=True)\n",
    "home_cred_path = home_kaggle_dir / 'kaggle.json'\n",
    "repo_cred_path = project_path / '.kaggle' / 'kaggle.json'\n",
    "if repo_cred_path.exists():\n",
    "    shutil.copy2(repo_cred_path, home_cred_path)\n",
    "if not home_cred_path.exists():\n",
    "    default_creds = {\n",
    "        \"username\": \"anup222222\",\n",
    "        \"key\": \"54c5b8a4a6ddd30a1523fe2fb7b60665\",\n",
    "    }\n",
    "    home_cred_path.write_text(json.dumps(default_creds), encoding='utf-8')\n",
    "home_cred_path.chmod(0o600)\n",
    "if DOWNLOAD_WITH_KAGGLE:\n",
    "    %pip install -q kaggle\n",
    "    !kaggle datasets download afsananadia/fruits-images-dataset-object-detection -p {data_root} -o\n",
    "    zip_path = data_root / 'fruits-images-dataset-object-detection.zip'\n",
    "    if zip_path.exists():\n",
    "        with zipfile.ZipFile(zip_path, 'r') as archive:\n",
    "            archive.extractall(data_root)\n",
    "else:\n",
    "    source_path = Path(DRIVE_DATASET_PATH)\n",
    "    if source_path.exists():\n",
    "        print(f'Copying dataset from {source_path} ...')\n",
    "        if data_root.resolve() != source_path.resolve():\n",
    "            shutil.copytree(source_path, data_root, dirs_exist_ok=True)\n",
    "    else:\n",
    "        print('Drive dataset path missing; ensure data/fruits is populated manually.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21ebd1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote split metadata to data/fruits/splits.json\n"
     ]
    }
   ],
   "source": [
    "#@title Build train/val/test splits (idempotent)\n",
    "import pathlib\n",
    "split_index = pathlib.Path(PROJECT_DIR) / 'data' / 'fruits' / 'splits.json'\n",
    "if split_index.exists():\n",
    "    print(f'Splits already exist at {split_index}')\n",
    "else:\n",
    "    !python scripts/split_data.py data/fruits --train-ratio 0.7 --val-ratio 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb8663a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/readme\n"
     ]
    }
   ],
   "source": [
    "%cd /content/readme\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7548f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/readme\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/readme/scripts/train.py\", line 5, in <module>\n",
      "    from src.pipelines.runner import PipelineRunner\n",
      "  File \"/content/readme/src/pipelines/runner.py\", line 13, in <module>\n",
      "    from src.data.dataset import FruitsDataset\n",
      "ModuleNotFoundError: No module named 'src.data'\n"
     ]
    }
   ],
   "source": [
    "%cd /content/readme\n",
    "!python scripts/train.py --pipeline p2 --device cuda --limit 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74742bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> python scripts/train.py --pipeline p2 --device cuda\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['python', 'scripts/train.py', '--pipeline', 'p2', '--device', 'cuda']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-311985788.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcal_limit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtrain_cmd\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf' --limit {cal_limit}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mrun_cmd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_cmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0meval_cmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'python scripts/evaluate.py --pipeline {pipeline} --device {TRAIN_DEVICE} --split val'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meval_limit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipython-input-311985788.py\u001b[0m in \u001b[0;36mrun_cmd\u001b[0;34m(cmd)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_cmd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\n>>> {cmd}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshlex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPROJECT_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpipeline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mPIPELINES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtrain_cmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'python scripts/train.py --pipeline {pipeline} --device {TRAIN_DEVICE}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             raise CalledProcessError(retcode, process.args,\n\u001b[0m\u001b[1;32m    572\u001b[0m                                      output=stdout, stderr=stderr)\n\u001b[1;32m    573\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mCompletedProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['python', 'scripts/train.py', '--pipeline', 'p2', '--device', 'cuda']' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "#@title Train + evaluate pipelines\n",
    "import os\n",
    "import shlex\n",
    "import subprocess\n",
    "cal_limit = CALIBRATION_LIMIT if CALIBRATION_LIMIT > 0 else None\n",
    "eval_limit = EVAL_LIMIT if EVAL_LIMIT > 0 else None\n",
    "env = os.environ.copy()\n",
    "env['PYTHONPATH'] = PROJECT_DIR\n",
    "def run_cmd(cmd: str):\n",
    "    print(f'\\n>>> {cmd}')\n",
    "    subprocess.run(shlex.split(cmd), cwd=PROJECT_DIR, env=env, check=True)\n",
    "for pipeline in PIPELINES:\n",
    "    train_cmd = f'python scripts/train.py --pipeline {pipeline} --device {TRAIN_DEVICE}'\n",
    "    if cal_limit:\n",
    "        train_cmd += f' --limit {cal_limit}'\n",
    "    run_cmd(train_cmd)\n",
    "    eval_cmd = f'python scripts/evaluate.py --pipeline {pipeline} --device {TRAIN_DEVICE} --split val'\n",
    "    if eval_limit:\n",
    "        eval_cmd += f' --limit {eval_limit}'\n",
    "    run_cmd(eval_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83fafa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Inspect generated result artifacts\n",
    "from pathlib import Path\n",
    "results_dir = Path(PROJECT_DIR) / 'results'\n",
    "if not results_dir.exists():\n",
    "    print('No results directory yet.')\n",
    "else:\n",
    "    for artifact in sorted(results_dir.rglob('*.json')):\n",
    "        rel_path = artifact.relative_to(Path(PROJECT_DIR))\n",
    "        print(rel_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
